{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b5886-fbfb-4893-b4c7-c6e66914d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eaf7c61-8047-4b87-bf1a-636e5b4e3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "CONTENT_DIR = Path.home() / 'Datasets' / 'unpackAI' / 'DL201-4.0' # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d5887-5400-4b46-85e4-9aa8add8706c",
   "metadata": {},
   "source": [
    "# Section 2: Image Data for CV\n",
    "<hr style=\"border:4px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ec7ec-1da1-4610-92b2-35e9fd629a67",
   "metadata": {},
   "source": [
    "SECTION GOALS AND OBJECTIVES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f695b53-15cc-487f-8253-d3ca048913b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759cbf84-cbe7-48cb-a556-731ca5465409",
   "metadata": {},
   "source": [
    "## Step 1: Loading Image Data\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3e637-a6a9-4c5d-8692-3f1b606f27c6",
   "metadata": {},
   "source": [
    "As is always, the question becomes, how do we access our data.\n",
    "\n",
    "How is it stored?\n",
    "\n",
    "In general, most computer vision data sets are organized in two ways.\n",
    "\n",
    "* As individual files \n",
    "\n",
    "* With Metadata (Tables which contain the information we need)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e21566-b098-4bb3-8ef3-ac67d374de03",
   "metadata": {},
   "source": [
    "To do this, we are going to walk through a couple datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e769eb4-201d-4a8d-8d08-2670b4166b8b",
   "metadata": {},
   "source": [
    "\n",
    "### Key Concept: File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c038fb90-d5a0-477e-a156-5d7d041990ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jentlejames/Datasets/unpackAI/DL201-4.0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccad457-2dab-4f97-9675-0c3a8403511a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d9727-ebe3-4a2f-82e6-9bd75f8cafe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb5bb6-13e3-4075-8de8-3c60eb538c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3abbfd8-830d-42ff-a1b0-d811c2358fe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Case 1: Data points as Individual files\n",
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daca1b6-ee6a-4fab-8fa1-40ded1c13f21",
   "metadata": {},
   "source": [
    "For this case, we are going to show how images are often organized \n",
    ":\n",
    "in directories, and how we can extract our data.\n",
    "\n",
    "As always, we need to be thinking about the following ideas \n",
    "\n",
    "* What are the potential target variables or labels?\n",
    "\n",
    "* What are  the potentia feature variables in the dataset? How are they relevant?\n",
    "\n",
    "* {{Continue to add more questions}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f7dfc-cf4d-493b-a218-287f24b5cc01",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Extracting Zip Files\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "Zip files are incredibly common in many areas.\n",
    "\n",
    "For datasets, they serve two primary purposes\n",
    "\n",
    "1. This format bundles together many files into one and makes it easier and faster to send it over the internet. Network protocols are similar to the mail. It's much less complicated to send a shipping container rather than do paperwork and handling of thousands of individual boxes.\n",
    "\n",
    "2. Compression. The other problem is bandwidth. Zip files, along with other formats, can make files smaller which is beneficial because they take up less space on the hard drive. More importantly, this means that we can download the dataset faster. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce86a1-eebd-43da-ac82-21ad91e3f59d",
   "metadata": {},
   "source": [
    "##### Step 1: Find the exact file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d30fe871-6b00-4c68-91b1-eda2d4fbb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the file path using pathlib\n",
    "\n",
    "emotionsImagesZipPath = CONTENT_DIR /'opencv-emotion-images.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbcbeb-500e-4a58-b87c-6f69d94fb8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f1bff-598b-4688-939d-1b8b8f9fe6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a96b891-2205-4755-b138-20ad8aa07096",
   "metadata": {},
   "source": [
    "##### Step 2: Unzip the files\n",
    "\n",
    "In this code, we are using a library called shutil\n",
    "Shutil is short for shell utility.\n",
    "\n",
    "This allows python to make commands in the shell like we learned earlier.\n",
    "\n",
    "In this case, we are telling it to unzip a file at location X and put it into location Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e085b961-8e37-4a42-a67f-79d70fb2d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzipping Zip files in Python\n",
    "import os\n",
    "from shutil import unpack_archive\n",
    "\n",
    "#unpack_archive(emotionsImagesZipPath, CONTENT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41a79c-5faa-4508-ad46-ac3832be37e2",
   "metadata": {},
   "source": [
    "##### Step 3: Check the file path\n",
    "\n",
    "\n",
    "\n",
    "Now that we extracted the data, we now need to make sure that we know where our data is, and check up on it before proceeding to the next level.\n",
    "\n",
    "Check the output of the next command and see what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4f5b0ba-9ac8-43ac-b90f-ddb89d2b9c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CV', 'NLP', 'bank_loan', 'zips', 'TAB', 'emotion-images']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.listdir(CONTENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36400c8c-1b13-4f35-a85d-8eaccd5e1915",
   "metadata": {},
   "source": [
    "The directory is called 'images'\n",
    "\n",
    "This is not very clear, so we should rename it so that\n",
    "our data never gets lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2afef67-1cfe-46d7-8138-b8f888d74b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(CONTENT_DIR/ 'Images',CONTENT_DIR / 'emotion-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4203e53d-3246-4a7c-a1aa-ec29726abb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's change the directory we are working in \n",
    "os.chdir(CONTENT_DIR/ 'emotion-images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d64997-3b4a-4804-92cf-d184307a8283",
   "metadata": {},
   "source": [
    "Now that we have unzipped our dataset, we can proceed to see \n",
    "what is inside of it. We should look for our labels first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d16fab-c532-459f-b2db-574a765cc3d7",
   "metadata": {},
   "source": [
    "#### Skill 1 : Extracting labels from Directory Names\n",
    "<hr style=\"border:0.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6b1b3-b1fa-410f-b145-6390d786f0d0",
   "metadata": {},
   "source": [
    "The next thing we need to do is to find the labels in our dataset.\n",
    "\n",
    "remember the y = mx + b example. We need to tell the AI model what the target for prediction will be.\n",
    "\n",
    "In this case, the labels are organized as file paths. Let's take a look here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fab7f5-2914-4bb8-8d82-08fce1a5fe4f",
   "metadata": {},
   "source": [
    "##### Step 1: Find the root directory\n",
    "\n",
    "File systems are often refered to as file trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "73936745-74c4-40c5-8700-59163142bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.chdir(CONTENT_DIR / 'emotion-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1f8cd73b-29fb-411c-b582-999059a478bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jentlejames/Datasets/unpackAI/DL201-3.0/emotion-images')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf522a1c-e0bf-45fc-886e-a2122317348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ad25710-d463-4018-ac15-a7bba01dc34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jentlejames/Datasets/unpackAI/DL201-3.0/emotion-images\n",
      "['validation', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(Path.cwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98293c96-1c47-4bb9-989d-e27ad8880cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "055bfb7a-f021-47c9-96a4-cad814d5af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jentlejames/Datasets/unpackAI/DL201-3.0/emotion-images/train\n",
      "['Fear', 'Angry', 'Neutral', 'Surprise', 'Happy', 'Sad', 'Disgust']\n"
     ]
    }
   ],
   "source": [
    "print(Path.cwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d71c42d-50ba-4d32-abfa-723d541d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = CONTENT_DIR/'emotion-images'/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2987502-08a6-4215-a3ef-e233d8d8a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12642e8f-6feb-4eb9-b724-93556ac1a834",
   "metadata": {},
   "source": [
    "Now we have our labels. Let's look at them and decide what we can do now with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b05eb43e-893d-47af-a0ff-e281dee1fd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of labels: 7\n"
     ]
    }
   ],
   "source": [
    "print(f'total number of labels: {len(labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03d482-7156-4616-be23-f03ab3d0daf1",
   "metadata": {},
   "source": [
    "#### EDA: Extracting file paths for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53b5e14c-962a-453e-a4ee-48a52a1141c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097\n",
      "3995\n",
      "4965\n",
      "3171\n",
      "7215\n",
      "4830\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "for label in os.listdir(TRAIN_DIR):\n",
    "    imagesDirectory = TRAIN_DIR/label\n",
    "    #print(directoryPath)\n",
    "    \n",
    "    images = os.listdir(imagesDirectory)\n",
    "    for imageName in images:\n",
    "        \n",
    "        imagePath = imagesDirectory/imagesPath # makes a longer path\n",
    "        \n",
    "        \n",
    "        imageName = imagePath \n",
    "    print(len(images))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edc657e7-bcad-4466-a592-34051ed07eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4097\n",
      "3995\n",
      "4965\n",
      "3171\n",
      "7215\n",
      "4830\n",
      "436\n",
      "dict_keys(['Fear', 'Angry', 'Neutral', 'Surprise', 'Happy', 'Sad', 'Disgust'])\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/content/drive/MyDrive/Colab Data\"\n",
    "base_dir = root_dir + '/Tomato_Sample'\n",
    "\n",
    "imagesDictionary = {}\n",
    "for label in labels:\n",
    "    classDir = TRAIN_DIR/label\n",
    "    classImagePathsList = [classDir/ImageName for ImageName in os.listdir(classDir)]\n",
    "    \n",
    "    print(len(classImagePathsList))\n",
    "    imagesDictionary[label] = classImagePathsList\n",
    "print(imagesDictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "848fbd93-ace4-4325-8e69-4e9ea818024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jentlejames/Datasets/unpackAI/DL201-3.0/emotion-images/train/Happy/5618.jpg')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesDictionary['Happy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c610f-0a10-4016-9a77-75106cc7f490",
   "metadata": {},
   "source": [
    "#### Skill 1 : Extracting labels from File Names\n",
    "<hr style=\"border:0.5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7ea4a2-6835-420c-bd2d-075ce5c34b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book\n",
    "\n",
    "from fastbook import *\n",
    "\n",
    "\n",
    "from fastai.data.external import URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22a22cf1-dad1-4446-82b5-6176e063f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfa3130-6a82-4db6-85bb-bd8f80820532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f498c5b-3d3f-4308-93da-1298496f8d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/jentlejames/.fastai/data/oxford-iiit-pet/images'),Path('/home/jentlejames/.fastai/data/oxford-iiit-pet/annotations')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fef899-63c1-4c9d-949a-322686d3df15",
   "metadata": {},
   "source": [
    "We can see that this dataset provides us with *images* and *annotations* directories. The [website](https://www.robots.ox.ac.uk/~vgg/data/pets/) for the dataset tells us that the *annotations* directory contains information about where the pets are rather than what they are. In this chapter, we will be doing classification, not localization, which is to say that we care about what the pets are, not where they are. Therefore, we will ignore the *annotations* directory for now. So, let's have a look inside the *images* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9afd03b-76f3-4c7d-9acc-a2163a251c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) [Path('images/Egyptian_Mau_33.jpg'),Path('images/english_setter_134.jpg'),Path('images/pug_99.jpg'),Path('images/staffordshire_bull_terrier_39.jpg'),Path('images/keeshond_27.jpg'),Path('images/shiba_inu_56.jpg'),Path('images/Sphynx_156.jpg'),Path('images/Ragdoll_74.jpg'),Path('images/american_pit_bull_terrier_18.jpg'),Path('images/Abyssinian_65.jpg')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/\"images\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb69b0-3474-4889-a8c9-5f08fa2f226a",
   "metadata": {},
   "source": [
    "Most functions and methods in fastai that return a collection use a class called `L`. `L` can be thought of as an enhanced version of the ordinary Python `list` type, with added conveniences for common operations. For instance, when we display an object of this class in a notebook it appears in the format shown there. The first thing that is shown is the number of items in the collection, prefixed with a `#`. You'll also see in the preceding output that the list is suffixed with an ellipsis. This means that only the first few items are displayed—which is a good thing, because we would not want more than 7,000 filenames on our screen!\n",
    "\n",
    "By examining these filenames, we can see how they appear to be structured. Each filename contains the pet breed, and then an underscore (`_`), a number, and finally the file extension. We need to create a piece of code that extracts the breed from a single `Path`. Jupyter notebooks make this easy, because we can gradually build up something that works, and then use it for the entire dataset. We do have to be careful to not make too many assumptions at this point. For instance, if you look carefully you may notice that some of the pet breeds contain multiple words, so we cannot simply break at the first `_` character that we find. To allow us to test our code, let's pick out one of these filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e6697c9-da96-4ee1-8e61-4ebe11b9bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = (path/\"images\").ls()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f397dc7-0812-4826-b371-349939076063",
   "metadata": {},
   "source": [
    "The most powerful and flexible way to extract information from strings like this is to use a *regular expression*, also known as a *regex*. A regular expression is a special string, written in the regular expression language, which specifies a general rule for deciding if another string passes a test (i.e., \"matches\" the regular expression), and also possibly for plucking a particular part or parts out of that other string. \n",
    "\n",
    "In this case, we need a regular expression that extracts the pet breed from the filename.\n",
    "\n",
    "We do not have the space to give you a complete regular expression tutorial here, but there are many excellent ones online and we know that many of you will already be familiar with this wonderful tool. If you're not, that is totally fine—this is a great opportunity for you to rectify that! We find that regular expressions are one of the most useful tools in our programming toolkit, and many of our students tell us that this is one of the things they are most excited to learn about. So head over to Google and search for \"regular expressions tutorial\" now, and then come back here after you've had a good look around. The [book's website](https://book.fast.ai/) also provides a list of our favorites.\n",
    "\n",
    "> a: Not only are regular expressions dead handy, but they also have interesting roots. They are \"regular\" because they were originally examples of a \"regular\" language, the lowest rung within the Chomsky hierarchy, a grammar classification developed by linguist Noam Chomsky, who also wrote _Syntactic Structures_, the pioneering work searching for the formal grammar underlying human language. This is one of the charms of computing: it may be that the hammer you reach for every day in fact came from a spaceship.\n",
    "\n",
    "When you are writing a regular expression, the best way to start is just to try it against one example at first. Let's use the `findall` method to try a regular expression against the filename of the `fname` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "399b4ece-7ee0-4e1f-ad28-5862287d3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Egyptian_Mau']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this, it is looking for any characters which preceed an underscore with\n",
    "# only digits and then a .jpg extension \n",
    "# The $ sign means that it is at the end of  the file\n",
    "\n",
    "re.findall(r'(.+)_\\d+.jpg$', fname.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331e2c5-9da7-4794-8b92-51e123c6fef0",
   "metadata": {},
   "source": [
    "This regular expression plucks out all the characters leading up to the last underscore character, as long as the subsequence characters are numerical digits and then the JPEG file extension.\n",
    "\n",
    "Now that we confirmed the regular expression works for the example, let's use it to label the whole dataset. fastai comes with many classes to help with labeling. For labeling with regular expressions, we can use the `RegexLabeller` class. In this example we use the data block API we saw in <<chapter_production>> (in fact, we nearly always use the data block API—it's so much more flexible than the simple factory methods we saw in <<chapter_intro>>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdd8d4a9-91ad-44bc-aa6d-d5f169cf6a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9070f3a-bcf9-41b5-b842-edd0f469ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r'(.+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c202c8b-8233-426a-8c9e-d3cff4b175fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7393\n",
      "7393\n"
     ]
    }
   ],
   "source": [
    "files = (path/\"images\").ls()\n",
    "labels = []\n",
    "for imgPath in files:\n",
    "    # print(type(img))\n",
    "    imgPath = str(imgPath)\n",
    "    \n",
    "    try:\n",
    "        dogBreed = re.search('/(.+)_\\d+.jpg$',imgPath)[1]\n",
    "    except:\n",
    "        pass\n",
    "    label = dogBreed.split('/')[-1]\n",
    "    #print(label)\n",
    "    labels.append(label)\n",
    "    \n",
    "# Checking the length\n",
    "print(len(files))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ad390ea-4c49-4991-b58a-fb29b67731f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RegexLabeller at 0x7fb25ff1f340>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743dfac-8423-4934-bde4-43b1dc6ef7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e904d192-d532-4d61-80ca-a0eab226528f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Example 3: A table of URLs\n",
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f432c4-df97-449d-a49f-14af2cebf729",
   "metadata": {},
   "source": [
    "It is also possible to  get the label and path information in a CSV file.\n",
    "\n",
    "In this case, the label extraction can be done using Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3224f54-2067-4a3f-911a-1ee92b90718a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb59aacb-d95f-465b-8d0e-48ae6d5b21a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "Type 3: A csv of labels and URLs\n",
    "\n",
    "This is a google landmarks image dataset, it contains lots of information on different photos that users have uploaded along with different kinds of metadata.\n",
    "\n",
    "However, the  dataset is quite large, so it makes more sense to download the paths individually\n",
    "\n",
    "These  metadata files contain the urls to the images that we will eventually ne\n",
    "\n",
    "\n",
    "##### ETL \n",
    "\n",
    "Step 1, identifying the x and the y \n",
    "\n",
    "Features in this case are the images\n",
    "\n",
    "Labels in this case are the  landmark IDs\n",
    "\n",
    "Now, we need to get these two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5019e911-6a15-49a9-b4c9-bd21f4df505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognition_solution.csv\n",
      "train.csv\n",
      "retrieval_solution.csv\n",
      "boxes_split2.csv\n",
      "index.csv\n",
      "test.csv\n",
      "boxes_split1.csv\n"
     ]
    }
   ],
   "source": [
    "# Type of computer vision datasets \n",
    "import os \n",
    "\n",
    "googleLandmarksPath = '/home/jentlejames/Datasets/Google-Landmarks/'\n",
    "\n",
    "for dirname, _, filenames in os.walk(googleLandmarksPath):\n",
    "    for filename in filenames: \n",
    "        print(filename)\n",
    "        filepath = os.path.join(dirname,filename)\n",
    "        filename = filename.split('.')[0]\n",
    "\n",
    "        exec(f\"{filename} = pd.read_csv('{filepath}')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3561e98-58cb-4806-9399-4033bd50be07",
   "metadata": {},
   "source": [
    "### Let's take a look at everything in our dataset using.head() and printing the shape\n",
    "\n",
    "We want to know  the shape, because as we learned in the last lesson, shape is very important.\n",
    "\n",
    "If we check the ratios of the shape and we find relationships, we can confirm that we have what we need\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06e4eb65-5314-4c6d-8792-2702e9ece00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117703, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b8a5057fdc51fb0a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0ae5b40187f3e6e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8102cf887daa75b9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id landmarks    Usage\n",
       "0  b8a5057fdc51fb0a       NaN  Private\n",
       "1  a0ae5b40187f3e6e       NaN   Public\n",
       "2  8102cf887daa75b9       NaN   Public"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recognition Solution\n",
    "\n",
    "print(recognition_solution.shape)\n",
    "recognition_solution.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54229647-5466-458e-9345-deb995579996",
   "metadata": {},
   "source": [
    "### Looking at the test and training data\n",
    "\n",
    "### let's look at the relationship between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "092bd43b-467e-4cfc-9b33-fb559f0aa896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225029, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97c0a12e07ae8dd5</td>\n",
       "      <td>http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650c989dd3493748</td>\n",
       "      <td>https://lh5.googleusercontent.com/-PUnMrX7oOyA...</td>\n",
       "      <td>12519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05e63ca9b2cde1f4</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  97c0a12e07ae8dd5  http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...   \n",
       "1  650c989dd3493748  https://lh5.googleusercontent.com/-PUnMrX7oOyA...   \n",
       "2  05e63ca9b2cde1f4  http://mw2.google.com/mw-panoramio/photos/medi...   \n",
       "\n",
       "  landmark_id  \n",
       "0        6347  \n",
       "1       12519  \n",
       "2         264  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "print(train.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "922bd5a3-7978-4208-9ad2-c195c000c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117703, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb9998b8cdaf6235</td>\n",
       "      <td>https://lh3.googleusercontent.com/-q8B91vDIQZY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30728cf6e50a6bc6</td>\n",
       "      <td>https://lh3.googleusercontent.com/-91gJSKTgv5Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16afbc86b710337d</td>\n",
       "      <td>https://lh3.googleusercontent.com/-GHZdXuf2wMg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d29b2166cf522450</td>\n",
       "      <td>https://lh3.googleusercontent.com/-cWDnYNQhyws...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd5c03b20c21cfba</td>\n",
       "      <td>https://lh3.googleusercontent.com/-PSLN6BloM-k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  cb9998b8cdaf6235  https://lh3.googleusercontent.com/-q8B91vDIQZY...\n",
       "1  30728cf6e50a6bc6  https://lh3.googleusercontent.com/-91gJSKTgv5Q...\n",
       "2  16afbc86b710337d  https://lh3.googleusercontent.com/-GHZdXuf2wMg...\n",
       "3  d29b2166cf522450  https://lh3.googleusercontent.com/-cWDnYNQhyws...\n",
       "4  dd5c03b20c21cfba  https://lh3.googleusercontent.com/-PSLN6BloM-k..."
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set\n",
    "\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a8d45df6-6eab-4b02-9970-096b51dc1df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test to train ratio is:\n",
      "10.407797592244888 to 1\n"
     ]
    }
   ],
   "source": [
    "print('test to train ratio is:')\n",
    "print(f'{train.shape[0] / test.shape[0]} to 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3ab86-57a4-41e4-a61e-9923bd30c771",
   "metadata": {},
   "source": [
    "### Now let's look at retrieval solution and use our intuition to see what it means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "728977e6-af84-4d04-9578-5b51f86435f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117703, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>images</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97a902dee49b61b4</td>\n",
       "      <td>None</td>\n",
       "      <td>Ignored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14289cc41c49feb0</td>\n",
       "      <td>None</td>\n",
       "      <td>Ignored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ccb0a36d5377d303</td>\n",
       "      <td>None</td>\n",
       "      <td>Ignored</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id images    Usage\n",
       "0  97a902dee49b61b4   None  Ignored\n",
       "1  14289cc41c49feb0   None  Ignored\n",
       "2  ccb0a36d5377d303   None  Ignored"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieval solution\n",
    "\n",
    "print(retrieval_solution.shape)\n",
    "retrieval_solution.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597f97a-ec60-4fbe-8a02-96893bf5b4b1",
   "metadata": {},
   "source": [
    "It seems like there are two new categories, images and usage\n",
    "\n",
    "let's see what is inside of them in \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7dedc06-85c2-4600-a796-0dae1cc2e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ignored    116984\n",
       "Private       483\n",
       "Public        236\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retrieval_solution.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fb3e4-3912-4d65-8be2-6930ccc5f700",
   "metadata": {},
   "source": [
    "This  likely means that some of the images will not be downloadable because they are private. In this case, we have have to drop these images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ddb5614-f5ea-4cda-a5f4-ca6a18bd9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it seems that there are 445 unique entries for this category\n",
    "\n",
    "len(retrieval_solution.images.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b896b8a-f86f-454f-8daa-fa446165a7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94801142-b684-4458-81df-3e9dd4cfff72",
   "metadata": {},
   "source": [
    "## Step 3: EDA Exploring Image Datasets\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a71d71-c1fb-44aa-bb16-0993c228491b",
   "metadata": {},
   "source": [
    "Now that we have the image paths which tell us exactly where our data is, we can now explore them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28ae07-8168-466a-8300-5ee283e664ac",
   "metadata": {},
   "source": [
    "### Example 1: Displaying images in Jupyter Notebook\n",
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d603aa4-2f27-4640-8d5b-c4cfc15806af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cdde3bf7-209c-493c-a7e3-20b20675997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unpackai.utils import clean_error_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a510d-31a6-4dfb-afd0-dbb86b59b656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d60f70f2-bc97-4de2-b6af-89cb08c2f0bd",
   "metadata": {},
   "source": [
    "### Example 2: Checking for corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b893dd8-e937-4268-b0b7-1d14114adb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/436 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unpackai.utils import clean_error_img\n",
    "\n",
    "\n",
    "# This line checks for corrupted images\n",
    "clean_error_img(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa8e6e-54d6-4561-a623-2cc87ee920c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108edb3-316d-4331-9d3e-99c64ec4024c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be138206-d823-45c9-8378-6a5a8d82f457",
   "metadata": {},
   "source": [
    "### Example 3: Examining Metadata for Features and Labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75120a8c-68c9-4439-9f9e-7af31cb35117",
   "metadata": {},
   "source": [
    "Now that we have looked at the metadata here, let's extract the features and the labels. \n",
    "\n",
    "The key features in this are going to be the file paths, becuase it is going to allow us access to the photos so, we can download them from google's servers.\n",
    "\n",
    "This will be in the csv file for us to extract.\n",
    "\n",
    "The labels in this case are going to be the landmark_IDs. This will be key to our data analysis approach. \n",
    "\n",
    "If we are doing image segmentation we can also extract the box labels that will tell our data where the landmarks are located in the photos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c3755-8253-4981-bf82-e5e2794c0280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778623b7-4218-4a78-a78e-28db47ed36d8",
   "metadata": {},
   "source": [
    "#### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d1859-38d6-4925-adb4-fb55bc972bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5c8b2c0-e8f5-4a09-a4c8-6376a287b4af",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Text Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b777e90-2dcb-42e8-9157-2c5429420a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84014510-3c9d-4428-b646-a1948bf39dd4",
   "metadata": {},
   "source": [
    " Out of this, we need to find the label, and where the feature is located\n",
    "\n",
    " In my opinion, the landmark_ID is a potential target, along with the boxes if it becomes an image segmentation problem\n",
    "\n",
    " \n",
    "\n",
    " Let's learn more about the landmark_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4e93e21b-8169-4763-b19b-70dd57dc127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97c0a12e07ae8dd5</td>\n",
       "      <td>http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650c989dd3493748</td>\n",
       "      <td>https://lh5.googleusercontent.com/-PUnMrX7oOyA...</td>\n",
       "      <td>12519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05e63ca9b2cde1f4</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08672eddcb2b7c93</td>\n",
       "      <td>http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...</td>\n",
       "      <td>13287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc49cb32ef7f1e89</td>\n",
       "      <td>http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...</td>\n",
       "      <td>4018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  97c0a12e07ae8dd5  http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...   \n",
       "1  650c989dd3493748  https://lh5.googleusercontent.com/-PUnMrX7oOyA...   \n",
       "2  05e63ca9b2cde1f4  http://mw2.google.com/mw-panoramio/photos/medi...   \n",
       "3  08672eddcb2b7c93  http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...   \n",
       "4  fc49cb32ef7f1e89  http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...   \n",
       "\n",
       "  landmark_id  \n",
       "0        6347  \n",
       "1       12519  \n",
       "2         264  \n",
       "3       13287  \n",
       "4        4018  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "20403216-81c7-4bd1-a57d-072b79a9077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of unique images in train set\n",
      "14945\n"
     ]
    }
   ],
   "source": [
    "print('total of unique images in train set')\n",
    "print(len(train.landmark_id.unique()))\n",
    "#len(train.landmark_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3bdffa98-1cb1-48b6-824e-837009bdba3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None     70827\n",
       "9633     48550\n",
       "6051     47825\n",
       "6599     21777\n",
       "9779     17601\n",
       "         ...  \n",
       "4639         1\n",
       "4608         1\n",
       "11974        1\n",
       "6069         1\n",
       "7977         1\n",
       "Name: landmark_id, Length: 14945, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the landmark IDs\n",
    "landmarkIDs = pd.Series(train.landmark_id.value_counts())\n",
    "train.landmark_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5d90bbbb-1b8e-4592-a347-62b202fab79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70827, 48550, 47825, 21777, 17601, 12742, 10302,  8950,  8893])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlandmarkIDs.iloc[0:9].to_numpy() # Here is our numpy array which allows us to pass data to different libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8fa6804e-13d4-4ee1-9cf8-f72cd7752a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>70827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9633</td>\n",
       "      <td>48550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6051</td>\n",
       "      <td>47825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6599</td>\n",
       "      <td>21777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9779</td>\n",
       "      <td>17601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2061</td>\n",
       "      <td>12742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5554</td>\n",
       "      <td>10302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6651</td>\n",
       "      <td>8950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  landmark_id  count\n",
       "0        None  70827\n",
       "1        9633  48550\n",
       "2        6051  47825\n",
       "3        6599  21777\n",
       "4        9779  17601\n",
       "5        2061  12742\n",
       "6        5554  10302\n",
       "7        6651   8950"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the most frequent landmark_ids\n",
    "\n",
    "mostPhotographedLandmarks = landmarkIDs.to_numpy()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Occurance of landmark_id in decreasing order(Top categories)\n",
    "mostPhotographedLandmarks = pd.DataFrame(train.landmark_id.value_counts().head(8))\n",
    "mostPhotographedLandmarks.reset_index(inplace=True)\n",
    "mostPhotographedLandmarks.columns = ['landmark_id','count']\n",
    "mostPhotographedLandmarks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0163ae46-aa7a-4fcb-91e3-03a73738275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 8))\n",
    "plt.title('Most Photographed Landmarks')\n",
    "sns.barplot(x=\"landmark_id\", y=\"count\", data=mostPhotographedLandmarks,\n",
    "            label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8103f-f471-4fbd-b6fb-67c74232a323",
   "metadata": {},
   "source": [
    "This shows us an interesting part of the data, that the most common landmarkID is none\n",
    "\n",
    "This shows that it has no label and needs to be removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c9b9e9d1-d2f5-41bd-b327-22fb79fb3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking the length before removing these from our dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70827"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking f\n",
    "print('checking the length before removing these from our dataset')\n",
    "len(train) - len(train[train['landmark_id'] != 'None']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0e15807c-afce-4627-bb86-0b8a2b97653d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97c0a12e07ae8dd5</td>\n",
       "      <td>http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650c989dd3493748</td>\n",
       "      <td>https://lh5.googleusercontent.com/-PUnMrX7oOyA...</td>\n",
       "      <td>12519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05e63ca9b2cde1f4</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08672eddcb2b7c93</td>\n",
       "      <td>http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...</td>\n",
       "      <td>13287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc49cb32ef7f1e89</td>\n",
       "      <td>http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...</td>\n",
       "      <td>4018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225024</th>\n",
       "      <td>4bb5a501e5b26a6a</td>\n",
       "      <td>https://lh6.googleusercontent.com/-mRrQU3t5cYw...</td>\n",
       "      <td>9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225025</th>\n",
       "      <td>2cd8a404796cfe0e</td>\n",
       "      <td>https://lh6.googleusercontent.com/-0UB5gFx6w7M...</td>\n",
       "      <td>7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225026</th>\n",
       "      <td>8733b8b469fb8c1b</td>\n",
       "      <td>http://lh3.ggpht.com/-TDQWNVvJQDI/SI3HZSA4D3I/...</td>\n",
       "      <td>13170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225027</th>\n",
       "      <td>14dd9e8790397c83</td>\n",
       "      <td>https://lh4.googleusercontent.com/-anV4Xpo0UuM...</td>\n",
       "      <td>5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225028</th>\n",
       "      <td>4303049d5a6b5602</td>\n",
       "      <td>https://lh6.googleusercontent.com/-1pe3ldzCDAw...</td>\n",
       "      <td>4987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                                url  \\\n",
       "0        97c0a12e07ae8dd5  http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...   \n",
       "1        650c989dd3493748  https://lh5.googleusercontent.com/-PUnMrX7oOyA...   \n",
       "2        05e63ca9b2cde1f4  http://mw2.google.com/mw-panoramio/photos/medi...   \n",
       "3        08672eddcb2b7c93  http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...   \n",
       "4        fc49cb32ef7f1e89  http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...   \n",
       "...                   ...                                                ...   \n",
       "1225024  4bb5a501e5b26a6a  https://lh6.googleusercontent.com/-mRrQU3t5cYw...   \n",
       "1225025  2cd8a404796cfe0e  https://lh6.googleusercontent.com/-0UB5gFx6w7M...   \n",
       "1225026  8733b8b469fb8c1b  http://lh3.ggpht.com/-TDQWNVvJQDI/SI3HZSA4D3I/...   \n",
       "1225027  14dd9e8790397c83  https://lh4.googleusercontent.com/-anV4Xpo0UuM...   \n",
       "1225028  4303049d5a6b5602  https://lh6.googleusercontent.com/-1pe3ldzCDAw...   \n",
       "\n",
       "        landmark_id  \n",
       "0              6347  \n",
       "1             12519  \n",
       "2               264  \n",
       "3             13287  \n",
       "4              4018  \n",
       "...             ...  \n",
       "1225024        9737  \n",
       "1225025        7758  \n",
       "1225026       13170  \n",
       "1225027        5669  \n",
       "1225028        4987  \n",
       "\n",
       "[1154202 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "efe013ae-0305-4d92-a1a3-14063dc4d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to do an indexing of our data \n",
    "# in order to filter it, this selects the index where None is not included\n",
    "\n",
    "train = train[train['landmark_id'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ae2312be-a272-4732-82f6-0cce578316c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, url, landmark_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if our operation was completed \n",
    "\n",
    "train[train['landmark_id'] == 'None']\n",
    "#Nothing should show up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101c2a9-0ca0-40de-90de-151deeaba0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5250b833-1d5b-446e-9be9-29cf1baab921",
   "metadata": {},
   "source": [
    "#### Boxes (Image Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7bccb-8057-4a6d-a325-fef79e28c112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d490122-7399-4a77-a0fe-42729df55776",
   "metadata": {},
   "source": [
    "Boxes labels\n",
    "\n",
    " it appears that some of the images have boxes labeled\n",
    "\n",
    "This would be useful if we are trying to do image segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0e50b73b-5d2a-485c-84dd-81c256627483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53755, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03b4355b047c94b4</td>\n",
       "      <td>0.12 0.16 0.74 1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>435986fb31b5f4f3</td>\n",
       "      <td>0.37 0.35 0.52 0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a8e1490b5f8d37e2</td>\n",
       "      <td>0.22 0.00 0.87 1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                  box\n",
       "0  03b4355b047c94b4  0.12 0.16 0.74 1.00\n",
       "1  435986fb31b5f4f3  0.37 0.35 0.52 0.40\n",
       "2  a8e1490b5f8d37e2  0.22 0.00 0.87 1.00"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boxes Split 1 \n",
    "\n",
    "print(boxes_split1.shape)\n",
    "boxes_split1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2e2ceae3-42d9-4a60-baa9-3eb54592c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.76048697187598 % are labeled with boxes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255883c7-d4dd-4640-a9a8-55f9c47220f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32328, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eabff78ee97cf8df</td>\n",
       "      <td>0.00 0.00 0.79 0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>654a08dff4f19f5b</td>\n",
       "      <td>0.00 0.04 0.96 1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6228cc96dc5b4def</td>\n",
       "      <td>0.00 0.23 0.75 0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                  box\n",
       "0  eabff78ee97cf8df  0.00 0.00 0.79 0.95\n",
       "1  654a08dff4f19f5b  0.00 0.04 0.96 1.00\n",
       "2  6228cc96dc5b4def  0.00 0.23 0.75 0.76"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boxes Split 2\n",
    "\n",
    "print(boxes_split2.shape)\n",
    "boxes_split2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef71b3-ab6a-4ebf-8249-e723d2681007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'{(index.shape[0] / (boxes_split1.shape[0] + boxes_split2.shape[0]))} % are labeled with boxes' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64405c8-35de-484a-83cc-404cdc59f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098461, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e08bbc99a449d6e6</td>\n",
       "      <td>http://lh3.ggpht.com/-0syNYGY8KGI/TM3Y0kKbgDI/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d8adc613d77254d5</td>\n",
       "      <td>https://lh3.googleusercontent.com/-gvOm8lpizSQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb4a99310d191a7a</td>\n",
       "      <td>http://lh5.ggpht.com/-2NdVC7qAtk4/SC9AW2SGWqI/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url\n",
       "0  e08bbc99a449d6e6  http://lh3.ggpht.com/-0syNYGY8KGI/TM3Y0kKbgDI/...\n",
       "1  d8adc613d77254d5  https://lh3.googleusercontent.com/-gvOm8lpizSQ...\n",
       "2  bb4a99310d191a7a  http://lh5.ggpht.com/-2NdVC7qAtk4/SC9AW2SGWqI/..."
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index \n",
    "print(index.shape)\n",
    "index.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048aa88-2ebd-4125-a5f4-cbaaad6ac3b7",
   "metadata": {},
   "source": [
    " Out of this, we need to find the label, and where the feature is located\n",
    "\n",
    " In my opinion, the landmark_ID is a potential target, along with the boxes if it becomes an image segmentation problem\n",
    "\n",
    "\n",
    "\n",
    "Let's learn more about the landmark_ID by downloading a small sample of images that we can use to know more about the data we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ffb928-bf52-4aac-96a3-aee53c57a1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5470a4e-df3f-4c99-beb2-8e1741e7dfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9c8e89-4bf0-4409-9baf-85cec5572579",
   "metadata": {},
   "source": [
    "## Exploring the Data using a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258254f-8ca7-48ec-90c3-579d594399bd",
   "metadata": {},
   "source": [
    "Due to many advancements in deep learning, it has become much easier for us to be able to use tools people have created to inform the rest of our development process. In this case, we can put our data into a model to see how well it performs and what we need to do in order to make it better during the rest of our project.\n",
    "\n",
    "This will help us to iterate faster and make sure that our efforts are on right mark moving forward. This can save us a lot of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78acb4a-61dc-4d5f-a2c5-e53a47458217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "#hide\n",
    "from fastbook import *\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9fc60-8198-4441-9857-4dd6eae0e9c3",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "If our data is stored in google colab we can use the following code as a template to  upload it.\n",
    "\n",
    "The goal here is to get the file paths or our x variable (which is the images)\n",
    "\n",
    "along with the y variable which is the lable contained in the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ac9541-e50b-44c1-8f87-22a0eb78615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "530e71ee-87fa-401d-867b-d0f887131336",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'content/drive/MyDrive/{{{YOUR DATA DIRECTORY HERE}}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591a48d-cbba-458f-828e-a702ef3217e4",
   "metadata": {},
   "source": [
    "### Obtaining the Labels/Classes\n",
    "\n",
    "The next thing that you can do is know what classes you will be using, along with the individual file paths to each image. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e8dbc-2b82-4ca4-975a-0eda19efd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory which everything is stored in\n",
    "\n",
    "BASE_DIR = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f54ad-a821-4186-8099-fe52ee771cef",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Once we have our images in a path, we can use a dataloader to preprocess and transform the data automatically for us using FastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "781c444d-f070-4cab-ace3-ad701098823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaders(GetAttr):\n",
    "  def __init__(self, *loaders): self.loaders = loaders\n",
    "  def __getitem__(self, i): return self.loaders[i]\n",
    "  train,valid = add_props(lambda i, self: self[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e17212-4cdf-4316-8c32-eb18f641a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBlock (\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter = RandomSplitter(valid_pct=0.2, seed=99),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(225,225)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fe75a35-93b8-457e-adc2-91504afaa059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.new(\n",
    "    item_tfms=RandomResizedCrop(28, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7a4d1-f5a6-4953-8b47-ac86b034d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = EEGs.dataloaders(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71468d48-f41a-40a9-8d17-972bc34e4bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34d90b4-88a1-4b01-854f-fba782a6e536",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c31609-a231-43c9-8113-663e7e69aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b42d61-c0d1-4557-aa28-29969807a994",
   "metadata": {},
   "source": [
    "### Interpreting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "532e8a73-a2a8-494d-b4ec-83b398109b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa0ba3-9eb6-4edf-b71a-3c73c2664953",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67eb5d-c3d5-4faf-9c38-76f2c25651c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d076a9-b1da-41eb-b05c-d70e336d7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d2a83-aa72-484f-b05f-d6af9f408192",
   "metadata": {},
   "source": [
    "### Human in the Loop: \n",
    "\n",
    "Here, we can find what we have with the raw data and decide how we can improve it. The essence of Open Source is for people to share tools that will allow people to reach  greater highs than if they had to do everything from scratch. \n",
    "\n",
    "Where does the model perform well? How does it perform poorly? How can it be improved?\n",
    "\n",
    "Is this dataset suitable for what you are trying to learn and accomplish?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e624c7e-d3f5-4764-90cc-d2f3ffe25a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unpackAIdev",
   "language": "python",
   "name": "unpackaidev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
